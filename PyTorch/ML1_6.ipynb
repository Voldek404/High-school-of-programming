{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ov4K97EJbu4"
   },
   "source": [
    "# **Занятие 6. Свёрточные нейронные сети. Классификация цветных изображений**\n",
    "\n",
    "https://vk.com/lambda_brain\n",
    "\n",
    "Рассмотрим случай, когда входные данные -- это цветные изображения. Для обработки таких данных были придуманы **свёрточные нейронные сети**, воспользуемся для этого одной из классических моделей.\n",
    "\n",
    "---\n",
    "\n",
    "Импортируем нужные пакеты:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8abpHoRq6V-L",
    "ExecuteTime": {
     "end_time": "2025-11-26T20:49:56.218888Z",
     "start_time": "2025-11-26T20:49:56.215930Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n"
   ],
   "outputs": [],
   "execution_count": 229
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goNhmuPOJ-BV"
   },
   "source": [
    "Будем обрабатывать стандартный датасет **CIFAR10**, который включает фотографии десяти классов: самолёт, автомобиль, птица, кот, олень, собака, лягушка, лошадь, корабль и грузовик. На каждый класс приходится по 6000 (5000 обучающих и 1000 тестовых) цветных изображений размером 32 * 32 пиксела (и три канала цветности RGB)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UfwVbruB8gQb",
    "ExecuteTime": {
     "end_time": "2025-11-26T20:49:56.226148Z",
     "start_time": "2025-11-26T20:49:56.223700Z"
    }
   },
   "source": [
    "input_size = 3*32*32   # Размер изображения в точках * количество цветов\n",
    "num_classes = 10       # Количество распознающихся классов (10 видов изображений)\n",
    "n_epochs = 5           # Количество эпох\n",
    "batch_size = 16         # Размер мини-пакета входных данных\n",
    "lr = 0.001             # Скорость обучения"
   ],
   "outputs": [],
   "execution_count": 230
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPSaBAmrKJ5p"
   },
   "source": [
    "Из-за специфики представления цветных изображений мы не можем сразу брать их в сыром виде: сперва требуется нормализовать картинки, превратить их в изображения с интенсивностью цвета в диапазоне 0..1. Это делает стандартная функция **Normalize()** из torchvision.transforms, которой в качестве параметров в подобных случаях обычно указываются стандартные значения (среднее и стандартное отклонение) для такой нормализации (0.5, 0.5, 0.5).\n",
    "\n",
    "То есть нам нужно выполнить композицию трансформаций: сперва выполнить преобразование в тензоры, и затем нормализовать.\n",
    "\n",
    "Композицию выполняет стандартная функция torchvision.transforms **.Compose()**. Её результат мы и задаём в качестве параметра transform конструктора CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0eX2jdtCLzWd",
    "ExecuteTime": {
     "end_time": "2025-11-26T20:49:56.934083Z",
     "start_time": "2025-11-26T20:49:56.230084Z"
    }
   },
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))  # нормализация\n",
    "])\n",
    "\n",
    "cifar_trainset = dsets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n"
   ],
   "outputs": [],
   "execution_count": 231
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbncbyBiKid7"
   },
   "source": [
    "Аналогично подготовим и тестовый датасет:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8jKhtNW7L7YI",
    "ExecuteTime": {
     "end_time": "2025-11-26T20:49:57.568468Z",
     "start_time": "2025-11-26T20:49:56.940936Z"
    }
   },
   "source": [
    "cifar_testset = dsets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "print(len(cifar_trainset))\n",
    "print(len(cifar_testset))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "execution_count": 232
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lug1CvTJKmHb"
   },
   "source": [
    "Загрузим наши данные:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "brvDSwBVNqqS",
    "ExecuteTime": {
     "end_time": "2025-11-26T20:49:57.577762Z",
     "start_time": "2025-11-26T20:49:57.571934Z"
    }
   },
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=cifar_trainset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=cifar_testset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 233
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeC-wQZ0KpJq"
   },
   "source": [
    "Добавим стандартный шаг обучения:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TCBltxfGOChj",
    "ExecuteTime": {
     "end_time": "2025-11-26T20:49:57.583426Z",
     "start_time": "2025-11-26T20:49:57.580934Z"
    }
   },
   "source": [
    "# импортируем нужные библиотеки\n",
    "import torch\n",
    "import numpy as np # всегда пригодится :)\n",
    "from torch.nn import Linear, Sigmoid\n",
    "\n",
    "# инициализируем девайс\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# добавляем типовую функцию \"шаг обучения\"\n",
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        model.train()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step"
   ],
   "outputs": [],
   "execution_count": 234
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdK0PPStSWwH"
   },
   "source": [
    "Какую задействовать модель? Вообще, конструирование наиболее эффективных моделей -- это искусство плюс математика. На практике часто можно пользоваться либо простыми стандартными решениями (как было например в случае распознавания рукописных цифр), либо сложными моделями, которые под соответствующие классы задач придумали ведущие специалисты в ML.\n",
    "В нашем случае мы применим модель LeNet, предложенную Яном ЛеКуном -- она относится к так называемым **свёрточным нейронным сетям (Convolutional Neural Network, CNN)**, хорошо работающим с двумерными изображениями.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Подробное описание принципов работы CNN:\n",
    "\n",
    "https://neurohive.io/ru/tutorial/cnn-na-pytorch/\n",
    "\n",
    "Главное, обратите внимание на принцип **свёртки** и движущееся окно/**фильтр**.\n",
    "\n",
    "**Пулинг (pooling)** -- это схожая со скользящим окном техника, когда вместо свёртки по обучаемым весам к значениям в окне применяется некоторая статистическая функция (среднее, максимум, ...). Так, популярная механика тут -- это max pooling. Пулинг выполняет обобщение мелких деталей, устойчиво выделяет некоторый признак независимо от его размера и ориентации.\n",
    "\n",
    "**Канал** -- это множество фильтров, формирующих оригинальный двумерный вывод. Каналы нередко связываются с цветностью изображения.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XVIF0OHjvkRW",
    "ExecuteTime": {
     "end_time": "2025-11-26T20:49:57.590087Z",
     "start_time": "2025-11-26T20:49:57.586084Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CifarModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 235
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoZi7iOLTDUH"
   },
   "source": [
    "Рассмотрим структуру этой модели подробнее.\n",
    "\n",
    "По мелким техническим причинам (необходимость выравнивания данных при переходе от свёрточных слоёв к линейным) её удобнее представить в формате классической модели, а не просто композицией слоёв.\n",
    "\n",
    "Первый слой -- Conv2d(3, 6, 5) с функцией активации ReLU создаёт набор свёрточных фильтров. Первый параметр 3 -- это количество входных каналов изображений, три цвета. Второй параметр 6 -- это количество выходных каналов, третий параметр -- размер фильтра 5x5. На выходе получается 6 фильтров размером 3x5x5 -- и всего модель выделяет (3 * 5 * 5 + 1) * 6 = 456 параметров.\n",
    "Выходной размер слоя получится 6 * 28 * 28 , где 28 = ((32 - 5) + 1)\n",
    "\n",
    "Метод MaxPool2d(2,2) -- это реализация max-пулинга (вычисление его аргументов см. по ссылке выше). kernel_size -- размер окна пулинга, stride -- шаг пулинга. Выходной размер слоя таким образом снижаем в два раза: с 6 * 28 * 28 до 6 * 14 * 14.\n",
    "\n",
    "\n",
    "Далее снова применяется функция Conv2d(6, 16, 5) -- шесть выходных каналов предыдущей функций как входы. Теперь мы применяем 16 фильтров (каждый размером 6 * 5 * 5), и выходной размер слоя будет 16 * 10 * 10, где 10 = (14 - 5) + 1. Всего на уровне обрабатывается (5 * 5 * 6 + 1) * 16 = 2416 параметров.\n",
    "\n",
    "Следующий max pooling снижает этот выход в два раза -- с 16 * 10 * 10 до 16 * 5 * 5.\n",
    "\n",
    "И в заключение добавляются три полносвязных слоя Linear. Обратите внимание, что перед ними надо выполнить модификацию структуры передаваемых данных, так как свёрточные слои работают с двумерными изображениями, а линейные -- с векторными наборами. Такое преобразование выполняет x.view(-1, 16 * 5 * 5).\n",
    "\n",
    "Первый линейный слой из 120 узлов, получает 16 * 5 * 5 входов -- то есть в нём требуется (16 * 5 * 5 + 1) * 120 = 48120 параметров, и далее количество входов-выходов понижается через следующие слои до наших итоговых 10 классов (последний уровень требует (84+1) * 10 = 850 параметров).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZlW-CkjeOn2u",
    "ExecuteTime": {
     "end_time": "2025-11-26T20:59:46.123077Z",
     "start_time": "2025-11-26T20:49:57.593803Z"
    }
   },
   "source": [
    "from torch import optim, nn\n",
    "\n",
    "model = CifarModel()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        loss = train_step(images, labels)\n",
    "\n",
    "# print(model.state_dict())\n",
    "print(loss)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44167110323905945\n"
     ]
    }
   ],
   "execution_count": 236
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L-zC19n5X_-7",
    "ExecuteTime": {
     "end_time": "2025-11-26T20:59:58.110663Z",
     "start_time": "2025-11-26T20:59:46.138611Z"
    }
   },
   "source": [
    "with torch.no_grad(): # проверяем на тестовой выборке\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Точность: {} %'.format(100 * correct / total))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 73.26 %\n"
     ]
    }
   ],
   "execution_count": 237
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56Kd4ku8b-9b"
   },
   "source": [
    "Считаем точность -- она получается в районе 55%. Это хороший результат, так как при случайном выборе мы получили бы 10%. Причём её можно существенно повысить, увеличив число эпох обучения. Однако с помощью LeNet обычно с трудом удаётся достигнуть хотя бы 70%, для результата 80% и более лучше использовать например ResNet.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LX96AyHbcxSr"
   },
   "source": [
    "В заключение вычислим точность распознавания по каждому из признаков:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5LzRkaZXxb9k",
    "ExecuteTime": {
     "end_time": "2025-11-26T21:00:09.993436Z",
     "start_time": "2025-11-26T20:59:58.129874Z"
    }
   },
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    print('Точность для %5s : %2d %%' % (\n",
    "        labels[i], 100 * class_correct[i] / class_total[i]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность для tensor(7) : 75 %\n",
      "Точность для tensor(5) : 87 %\n",
      "Точность для tensor(8) : 60 %\n",
      "Точность для tensor(0) : 59 %\n"
     ]
    }
   ],
   "execution_count": 238
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVNjHoPddEUb"
   },
   "source": [
    "## **Задание.**\n",
    "Увеличение количества эпох (шагов обучения) существенно повышает качество модели. Но есть и другие способы -- поэкспериментируйте например с добавлением новых свёрточных или линейных слоёв, размерами фильтров и их количеством. В процессе экспериментов избегайте переобучения -- когда модель показывает отличные результаты на обучающей выборке, но невысокие на тестовой.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "В следующем занятии мы займёмся экспериментами с уже обученными моделями."
   ]
  }
 ]
}
